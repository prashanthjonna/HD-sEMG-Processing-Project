{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95ead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEYYY!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from itertools import combinations\n",
    "\n",
    "def apply_pca(X_train, X_test, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_train_pca = pca.fit_transform(X_train)\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    return X_train_pca, X_test_pca\n",
    "\n",
    "\n",
    "def apply_lda(X_train, y_train, X_test, n_components):\n",
    "    lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "    X_train_lda = lda.fit_transform(X_train, y_train)\n",
    "    X_test_lda = lda.transform(X_test)\n",
    "    return X_train_lda, X_test_lda\n",
    "\n",
    "\n",
    "def read_csv_and_preprocess(csv_file_path, input_columns, output_column):\n",
    "    \n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    df = df.dropna() \n",
    "    # Separate the input features and the output target\n",
    "    X = df[input_columns]\n",
    "    y = df[output_column]\n",
    "\n",
    "    #y = y.replace(['Push1.csv', 'Push2.csv', 'Push3.csv','Push.csv'], 'Push')\n",
    "    #y = y.replace(['Pull1.csv', 'Pull2.csv', 'Pull3.csv','Pull.csv'], 'Pull')\n",
    "    #y = y.replace(['Push'], 0)\n",
    "    #y = y.replace(['Pull'], 1)\n",
    "    # Perform any preprocessing steps (e.g., dealing with missing values, encoding categorical features)\n",
    "    #y = y.replace(['Flexion'], 0)\n",
    "    #y = y.replace(['Extension'], 1)\n",
    "    X = X.replace([\"Flexion\"],1)\n",
    "    X = X.replace([\"Extension\"],0)\n",
    "    \n",
    "    # Create an instance of OneHotEncoder\n",
    "    #encoder = OneHotEncoder()\n",
    "    # Fit and transform the categorical column\n",
    "    #encoded_data = encoder.fit_transform(df[['categorical_column']])\n",
    "    # Convert the encoded data to a DataFrame\n",
    "    #encoded_df = pd.DataFrame(encoded_data.toarray(), columns=encoder.get_feature_names_out(['categorical_column']))\n",
    "    # Concatenate the encoded DataFrame with the original DataFrame\n",
    "    #df_encoded = pd.concat([df, encoded_df], axis=1)\n",
    "    # Drop the original categorical column if needed\n",
    "    #df_encoded = df_encoded.drop(['Exercise type], axis=1)\n",
    "\n",
    "    #y = y.replace(['60.csv'], 0)\n",
    "    #y = y.replace(['90.csv'], 5)\n",
    "    #y = y.replace(['120.csv'], 10)\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Perform feature scaling if necessary\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, X, y\n",
    "\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "    return accuracy, classification_rep\n",
    "\n",
    "\n",
    "csv_file_path = './Data_Non_Functional.csv'\n",
    "input_columns = ['Flexion/Extension','Entropy_1','CoV_1','Intensity_1','Differential Intensity_1','Mean_RMS_1','Max_RMS_1','Mean_ARV_1','Max_ARV_1','Xcg_1','Ycg_1','Entropy_2','CoV_2','Intensity_2','Differential Intensity_2','Mean_RMS_2','Max_RMS_2','Mean_ARV_2','Max_ARV_2','Xcg_2','Ycg_2','Entropy_Ratio','CoV_Ratio','Mean_RMS_Ratio','Max_RMS_Ratio','Mean_ARV_Ratio','Max_ARV_Ratio','Intensity_Ratio','Differential_Instensity_Ratio']  \n",
    "#input_columns = ['Mean_RMS_1','Max_RMS_1','Xcg_1','Ycg_1','Mean_RMS_2','Max_RMS_2','Xcg_2','Ycg_2']  # Replace with the names of your input columns\n",
    "\n",
    "all_combinations = []\n",
    "\n",
    "print(\"HEYYY!\")\n",
    "\n",
    "min_combination_length = 3\n",
    "all_combinations = []\n",
    "for r in range(min_combination_length, len(input_columns) + 1):\n",
    "    all_combinations.extend([list(combo) for combo in combinations(input_columns, r)])\n",
    "\n",
    "print(\"HEYYYYYYYY!\")\n",
    "\n",
    "#input_columns = ['Entropy_Ratio','CoV_Ratio','Mean_RMS_Ratio','Max_RMS_Ratio','Mean_ARV_Ratio','Max_ARV_Ratio','Intensity_Ratio','Differential_Instensity_Ratio']  # 72 decision tree\n",
    "#input_columns = ['Mean_RMS_1','Max_RMS_1','Xcg_1','Ycg_1','Mean_RMS_2','Max_RMS_2','Xcg_2','Ycg_2']  # Replace with the names of your input columns\n",
    "output_column = 'Exercise type'  # Replace with the name of your output column\n",
    "#output_column = 'Flexion/Extension'  # Replace with the name of your output column\n",
    "#output_column = 'Exercise type'  # Replace with the name of your output column\n",
    "\n",
    "for input_comb in all_combinations:\n",
    "    \n",
    "    print(\"---------------------------\\n\\nFeatures : \",input_comb)\n",
    "\n",
    "    X_train, X_test, y_train, y_test, X, y = read_csv_and_preprocess(csv_file_path, input_comb, output_column)\n",
    "\n",
    "    # Apply PCA and LDA (you can adjust the number of components as needed)\n",
    "    #n_pca_components = 20  # Number of components for PCA\n",
    "    #n_lda_components = 1   # Number of components for LDA\n",
    "\n",
    "    #X_train, X_test = apply_pca(X_train, X_test, n_pca_components)\n",
    "    #le = LabelEncoder()\n",
    "    #y_train = le.fit_transform(y_train)\n",
    "    #X_train, X_test = apply_lda(X_train, y_train, X_test, n_lda_components)\n",
    "\n",
    "\n",
    "    models = {\n",
    "            'Logistic Regression': (LogisticRegression(), {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'solver': ['liblinear', 'lbfgs']\n",
    "            }),\n",
    "            'Decision Tree': (DecisionTreeClassifier(), {\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [None, 5, 10, 15, 20]\n",
    "            }),\n",
    "            'Random Forest': (RandomForestClassifier(), {\n",
    "                'n_estimators': [50, 100, 150],\n",
    "                'max_depth': [None, 5, 10, 15]\n",
    "            }),\n",
    "            'Support Vector Machine': (SVC(), {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'kernel': ['linear', 'rbf'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "            }),\n",
    "            #'Naive Bayes': (GaussianNB(), {}),\n",
    "            #'XGBoost': (xgb.XGBClassifier(), {\n",
    "            #    'learning_rate': [0.01, 0.1, 0.2],\n",
    "            #    'max_depth': [3, 5, 7, 9, 11],\n",
    "            #    'n_estimators': [50, 100, 150]\n",
    "            #}),\n",
    "            'K-Nearest Neighbors': (KNeighborsClassifier(), {\n",
    "                'n_neighbors': [1,5,10],\n",
    "                'weights': ['uniform', 'distance']\n",
    "            })\n",
    "        }\n",
    "\n",
    "    for model_name, (model, param_grid) in models.items():\n",
    "\n",
    "        if param_grid:\n",
    "            grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1)\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "            best_model = grid_search.best_estimator_\n",
    "            accuracy, classification_rep = train_and_evaluate_model(best_model, X_train, X_test, y_train, y_test)\n",
    "\n",
    "            print(f'Best {model_name} Model:')\n",
    "            print(f'Best hyperparameters: {grid_search.best_params_}')\n",
    "            print(f'Accuracy: {accuracy:.4f}')\n",
    "            #print(f'Classification Report:\\n{classification_rep}\\n')\n",
    "        else:\n",
    "            accuracy, classification_rep = train_and_evaluate_model(model, X_train, X_test, y_train, y_test)\n",
    "            print(f'{model_name} Model:')\n",
    "            print(f'Accuracy: {accuracy:.4f}')\n",
    "            #print(f'Classification Report:\\n{classification_rep}\\n')\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad33978d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
